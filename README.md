# K9
         Parks, downtowns, malls, and stores are places that we visit frequently in our day to day lives. These public venues are used for a multitude of different things such as socializing, dining, shopping, playing, etc. Therefore, it is important that these venues are easily accessible to EVERYONE. Out of the 7.5 billion that live on today's planet, around 285 million individuals suffer from visual impairment. Therefore, it is crucial that we make public venues accessible to 3% of our worldâ€™s population. This project focuses on creating a navigational aid, leveraging computer vision, artificial intelligence, robotics, and a variety of sensors, to make an ideal assistive technology for the visually impaired which they can use in public environments. The K9 includes many features, listed below:  A robotic navigation guide vehicle aid that would help the visually impaired and elderly navigate public indoor/outdoor surroundings Easily  able to control the speed of the guide vehicle Able to move on a predetermined path. The guided vehicle can move independently by detecting &amp; avoiding obstacles Able to Identify obstacles/various objects  Able to provide sound feedback           I decided to create a device on the Arduino platform, using a cheap computer vision camera and vibration motors for obstacle detection. After some research, I discovered the low-cost cmuCam5 Pixy Cam computer vision camera that is capable of recording signatures of objects. The device was able to detect pre-programmed obstacles, by its hue. Leveraging the Pixy Cam, ultrasonic sensor, and line follower, I created a device that can navigate a user around a store. This product can follow a predetermined path, avoid obstacles and come back on the path, and beep when it finds a specific object. Not only does this product navigate the user around a public environment, but it also identifies specific objects (i.e. tomato). In order to give more control of the robot to the user, a hand dynamometer was made that would allow the robot to change its speed based on the strength of one's hand.          To test my product, I replicated an indoor public environment using toy food, wood for aisles, and electrical tape for the predefined path. I tested my product three times for each nature of object detection: object on left, right, and both for a total of 9 trials. K-9 was 80% successful for objects on the left, 84.6% on the right, and 79% on left and right.           From my data, as well as qualitative observations, I can conclude that this product has the potential to help guide visually impaired individuals in public surroundings. Although it meets all of my criteria with an 82% accuracy, it will need to reach a 100% accuracy to hit the mainstream. In the future, I hope to leverage other types of computer vision cameras such as Google AIY to aid further in object identification.
